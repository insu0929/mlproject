{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.1307,),(0.3081,)), # mean value = 0.1307, standard deviation value = 0.3081\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = './MNIST'\n",
    "\n",
    "training_set = datasets.MNIST(root = data_path, train= True, download=True, transform= transform)\n",
    "testing_set = datasets.MNIST(root = data_path, train= False, download=True, transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classification, self).__init__()\n",
    "        \n",
    "        # construct layers for a neural network\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=20*20),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(in_features=20*20, out_features=10*10),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(in_features=10*10, out_features=10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
    "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
    "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
    "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
    "        out = self.classifier3(x)              # [batchSize, 10]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "classifier = classification().to(device)\n",
    "learning_rate_value = 0.01\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(epochs, tr_data_set, te_dataset):\n",
    "    tr_loss_Liters = []\n",
    "    tr_acc_Liters = []\n",
    "    te_loss_Liters = []\n",
    "    te_acc_Liters = []\n",
    "    \n",
    "    for i in range (epochs):\n",
    "        tr_avg_loss = 0\n",
    "        tr_avg_acc = 0\n",
    "        te_avg_loss =0\n",
    "        te_avg_acc = 0\n",
    "        \n",
    "        for x, y in tr_data_set:\n",
    "            x = x.view(-1, 28*28).to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = classifier(x)\n",
    "            tr_loss = criterion(y_pred, y)\n",
    "            tr_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tr_avg_loss += tr_loss / len(tr_data_set)\n",
    "            pred = torch.argmax(y_pred, 1) == y\n",
    "            tr_acc = pred.float().mean()\n",
    "            tr_avg_acc += tr_acc.item() / len(tr_data_set)\n",
    "            \n",
    "        for x,y in te_dataset:\n",
    "            x = x.view(-1, 28*28).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = classifier(x)\n",
    "            te_loss = criterion(y_pred, y)\n",
    "            \n",
    "            te_avg_loss += te_loss / len(te_dataset)\n",
    "            pred = torch.argmax(y_pred, 1) == y\n",
    "            te_acc = pred.float().mean()\n",
    "            te_avg_acc += te_acc.item() / len(te_dataset)\n",
    "            \n",
    "        \n",
    "        tr_loss_Liters.append(tr_avg_loss)\n",
    "        tr_acc_Liters.append(tr_avg_acc)\n",
    "        te_loss_Liters.append(te_avg_loss)\n",
    "        te_acc_Liters.append(te_avg_acc)\n",
    "        print(i)\n",
    "        \n",
    "    return tr_loss_Liters, tr_acc_Liters, te_loss_Liters, te_acc_Liters\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
